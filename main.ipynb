{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\medical_rag\\function.py:5: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from agent import retrieve_grader, question_rewriter\n",
      "d:\\RAG\\medical_rag\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\RAG\\medical_rag\\processing_document.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  text_embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from function import State, retrieve, evaluate_document, generate, transform_query, web_search, decide_next_step, update_history, retrieve_memory\n",
    "from conversationMemory import ConservationMemory\n",
    "from Retriever_memory import SemanticMemoryRetriever\n",
    "from langgraph.graph import START, END , StateGraph\n",
    "from format import format_response_for_display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConservationMemory()\n",
    "semantic_memory = SemanticMemoryRetriever()\n",
    "semantic_memory.add_memory(memory.get_all_history())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"retriever_memory\", retrieve_memory)\n",
    "workflow.add_node(\"retriever\", retrieve)\n",
    "workflow.add_node(\"grade_document\", evaluate_document)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search_tool\", web_search)\n",
    "workflow.add_node(\"update_history\", update_history)\n",
    "\n",
    "workflow.add_edge(START, \"retriever_memory\")\n",
    "workflow.add_edge(\"retriever_memory\", \"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"grade_document\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_document\",\n",
    "    decide_next_step,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\":\"generate\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search_tool\")\n",
    "workflow.add_edge(\"web_search_tool\", \"generate\")\n",
    "workflow.add_edge(\"generate\", \"update_history\")\n",
    "workflow.add_edge(\"update_history\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image, display\n",
    "#try:\n",
    "#    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "#except Exception:\n",
    "#    # This requires some extra dependencies and is optional\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with the Memory-Enhanced RAG system (type 'exit' to quit, 'clear' to clear current session)\n",
      "Loaded 8 previous interactions from memory\n",
      "---RETRIEVING MEMORIES---\n",
      "Retrieved 1 relevant memories\n",
      "--RETRIEVE--\n",
      "Query: mention the installation section\n",
      "Đã tìm thấy vector database với 7 mục, đang tải...\n",
      "Retrieved documents from main retriever: 5\n",
      "---Check document relevant to question---\n",
      "Evaluating document: IMAGE ANALYSIS:\n",
      "Okay, I will analyze the image acc...\n",
      "---Document relevant---\n",
      "Evaluating document: *   \\[12]: Warming table\n",
      "    *   \\[13]: Hand rest ...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: TEXT CONTENT:\n",
      "I. ĐIỀU KIỆN LẮP ĐẶT\n",
      "Chú ý: Không đặ...\n",
      "---Document relevant---\n",
      "Evaluating document: *   **Device Structure (Top Image):**\n",
      "    *   \\[1]...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: IMAGE ANALYSIS:\n",
      "Okay, I will analyze the provided ...\n",
      "---Document not relevant--- Score: no\n",
      "Web search recommended: 2/5 relevant docs\n",
      "---ASSESS DOCUMENT QUALITY---\n",
      "--DECISION: DOCUMENTS NOT SUFFICIENTLY RELEVANT, TRANSFORM QUERY---\n",
      "---Transform query---\n",
      "Error transforming query: \"Input to ChatPromptTemplate is missing variables {'document'}.  Expected: ['document', 'question'] Received: ['question']\\nNote: if you intended {document} to be part of the string and not a variable, please escape it with double curly braces like: '{{document}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"\n",
      "---WEB SEARCH---\n",
      "Added web search results (6 items)\n",
      "---GENERATE---\n",
      "Assistant: content='Okay, based on the provided document, here are the installation steps for the tissue embedding center:\\n\\n**Installation Section:**\\n\\n1.  **Location:** Choose an area with a flat surface, close to an electrical outlet, and with good ventilation.\\n2.  **Proximity:** Place the embedding module close to the cooling module. They can be placed right next to each other.\\n3.  **Switch Position:** Check that the switches of both modules are in the OFF (o) position.\\n4.  **Cable Connection:** Use a cable to connect the embedding module and the cooling module together.\\n5.  **Power Connection:** Connect the appropriate grounded power supply to both modules.  The power supply should be 230V 50Hz, with a socket load capacity of 10A or more.\\n\\n**Important Considerations (from the document):**\\n\\n*   **Avoid Direct Sunlight and Heat Sources:** Do not place the embedding system under direct sunlight or near a heat source.\\n*   **Avoid Humidity:** Avoid excessive air humidity.\\n*   **Avoid Electrical Interference:** Do not place the system in areas with electrical interference (such as near refrigerators, ultrasonic cleaners, microwave ovens, centrifuges).' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run-99e06b13-d293-49d7-8086-12487375a845-0' usage_metadata={'input_tokens': 2568, 'output_tokens': 252, 'total_tokens': 2820, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "---RETRIEVING MEMORIES---\n",
      "Retrieved 1 relevant memories\n",
      "--RETRIEVE--\n",
      "Query: Click on the button to select the active date\n",
      "Đã tìm thấy vector database với 7 mục, đang tải...\n",
      "Retrieved documents from main retriever: 5\n",
      "---Check document relevant to question---\n",
      "Evaluating document: Bấm chọn (màu xanh lá) để chọn ngày\n",
      "hoạt động hoặc...\n",
      "---Document relevant---\n",
      "Evaluating document: ngày tiếp theo.\n",
      "Sử dụng phím mũi trên để điều chỉn...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: **Operation:**\n",
      "1.  Operating mode\n",
      "2.  Quick heatin...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: TEXT CONTENT:\n",
      "1. Chế độ vận hành\n",
      "2. Chế làm nóng n...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document:  Cài đặt chế độ Auto:\n",
      "Nhấn chọn phím tùy chọn.\n",
      "Ch...\n",
      "---Document not relevant--- Score: no\n",
      "Web search recommended: 1/5 relevant docs\n",
      "---ASSESS DOCUMENT QUALITY---\n",
      "--DECISION: DOCUMENTS NOT SUFFICIENTLY RELEVANT, TRANSFORM QUERY---\n",
      "---Transform query---\n",
      "Error transforming query: \"Input to ChatPromptTemplate is missing variables {'document'}.  Expected: ['document', 'question'] Received: ['question']\\nNote: if you intended {document} to be part of the string and not a variable, please escape it with double curly braces like: '{{document}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"\n",
      "---WEB SEARCH---\n",
      "Added web search results (6 items)\n",
      "---GENERATE---\n",
      "Assistant: content='Click the green button to select the active date or the red button to select the off date.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run-d336286d-eaf3-493b-a6d8-f8aafb5acbd9-0' usage_metadata={'input_tokens': 2018, 'output_tokens': 19, 'total_tokens': 2037, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "---RETRIEVING MEMORIES---\n",
      "Retrieved 1 relevant memories\n",
      "--RETRIEVE--\n",
      "Query: Select which button to have the cooling block work at the same time as the tissue burying block.\n",
      "Đã tìm thấy vector database với 7 mục, đang tải...\n",
      "Retrieved documents from main retriever: 5\n",
      "---Check document relevant to question---\n",
      "Evaluating document: 9.  Option button\n",
      "10. Location of the cooling bloc...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: **Operation:**\n",
      "1.  Operating mode\n",
      "2.  Quick heatin...\n",
      "---Document relevant---\n",
      "Evaluating document: ngày tiếp theo.\n",
      "Sử dụng phím mũi trên để điều chỉn...\n",
      "---Document relevant---\n",
      "Evaluating document: *   \\[12]: Warming table\n",
      "    *   \\[13]: Hand rest ...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: IMAGE ANALYSIS:\n",
      "Okay, I will analyze the image acc...\n",
      "---Document not relevant--- Score: no\n",
      "Web search recommended: 2/5 relevant docs\n",
      "---ASSESS DOCUMENT QUALITY---\n",
      "--DECISION: DOCUMENTS NOT SUFFICIENTLY RELEVANT, TRANSFORM QUERY---\n",
      "---Transform query---\n",
      "Error transforming query: \"Input to ChatPromptTemplate is missing variables {'document'}.  Expected: ['document', 'question'] Received: ['question']\\nNote: if you intended {document} to be part of the string and not a variable, please escape it with double curly braces like: '{{document}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"\n",
      "---WEB SEARCH---\n",
      "Added web search results (6 items)\n",
      "---GENERATE---\n",
      "Assistant: content='Based on the document, to have the cooling block work at the same time as the tissue burying block, you should select \"**Auto Cryo**\".' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run-e7a7f053-bbf7-4930-827c-35b6814909ef-0' usage_metadata={'input_tokens': 2151, 'output_tokens': 32, 'total_tokens': 2183, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "---RETRIEVING MEMORIES---\n",
      "Retrieved 1 relevant memories\n",
      "--RETRIEVE--\n",
      "Query: Sử dụng phím mũi trên để điều chỉnh thời gian mong muốn. Bấm phím để lưu giá trị cài đặ\n",
      "Đã tìm thấy vector database với 7 mục, đang tải...\n",
      "Retrieved documents from main retriever: 5\n",
      "---Check document relevant to question---\n",
      "Evaluating document: ngày tiếp theo.\n",
      "Sử dụng phím mũi trên để điều chỉn...\n",
      "---Document relevant---\n",
      "Evaluating document: Bấm chọn (màu xanh lá) để chọn ngày\n",
      "hoạt động hoặc...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document:  Cài đặt chế độ Auto:\n",
      "Nhấn chọn phím tùy chọn.\n",
      "Ch...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: nhiệt độ môi trường)\n",
      "16. Thời gian bắt đầu (khi ở ...\n",
      "---Document not relevant--- Score: no\n",
      "Evaluating document: Nhấn chọn vị trí buồng đun paraffin\n",
      "Khi nhấn vào, ...\n",
      "---Document not relevant--- Score: no\n",
      "Web search recommended: 1/5 relevant docs\n",
      "---ASSESS DOCUMENT QUALITY---\n",
      "--DECISION: DOCUMENTS NOT SUFFICIENTLY RELEVANT, TRANSFORM QUERY---\n",
      "---Transform query---\n",
      "Error transforming query: \"Input to ChatPromptTemplate is missing variables {'document'}.  Expected: ['document', 'question'] Received: ['question']\\nNote: if you intended {document} to be part of the string and not a variable, please escape it with double curly braces like: '{{document}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"\n",
      "---WEB SEARCH---\n",
      "Added web search results (6 items)\n",
      "---GENERATE---\n",
      "Assistant: content='Bấm phím để lưu giá trị cài đặt.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run-0836510d-b4b1-423b-b7d9-3670b91dd3ed-0' usage_metadata={'input_tokens': 1963, 'output_tokens': 10, 'total_tokens': 1973, 'input_token_details': {'cache_read': 0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chat_with_rag():\n",
    "    print(\"Chat with the Memory-Enhanced RAG system (type 'exit' to quit, 'clear' to clear current session)\")\n",
    "    chat_history = memory.get_recent_history()\n",
    "    \n",
    "    print(f\"Loaded {len(memory.get_all_history())} previous interactions from memory\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        elif user_input.lower() == 'clear':\n",
    "            memory.clear_current_session()\n",
    "            chat_history = []\n",
    "            print(\"Current session cleared.\")\n",
    "            continue\n",
    "        \n",
    "        initial_state = {\n",
    "            \"question\": user_input,\n",
    "            \"chat_history\": chat_history,\n",
    "            \"document\": [],  \n",
    "            \"generation\": \"\", \n",
    "            \"web_search\": \"no\",  \n",
    "            \"memory_context\": \"\"  \n",
    "        }\n",
    "        \n",
    "        for output in app.stream(initial_state):\n",
    "            for key, value in output.items():\n",
    "                if key == \"update_history\":\n",
    "                    chat_history = value.get(\"chat_history\", [])\n",
    "                    print(f\"Assistant: {value.get('generation', '')}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_rag() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
